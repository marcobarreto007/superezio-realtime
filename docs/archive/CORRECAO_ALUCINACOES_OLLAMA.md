# üîß Corre√ß√£o de Alucina√ß√µes no Ollama

**Data:** 2025-11-12  
**Problema:** SuperEzio estava alucinando respostas (inventando arquivos, diret√≥rios, etc)  
**Causa Raiz:** Falta de par√¢metros de gera√ß√£o no Ollama + SYSTEM_PROMPT insuficiente

---

## üö® PROBLEMA IDENTIFICADO

O SuperEzio estava **inventando** informa√ß√µes:
- ‚ùå Listou arquivos que n√£o existem (`.gitignore`, `package.json`, `scripts/` no diret√≥rio `c/`)
- ‚ùå Respondeu sobre `/dev/cdrom` quando perguntado sobre disco C: (Windows)
- ‚ùå Inventou arquivos na √°rea de trabalho que n√£o existem

**Causa:** O modelo LLM (Ollama) estava gerando respostas criativas demais, sem seguir estritamente o contexto fornecido.

---

## ‚úÖ SOLU√á√ïES IMPLEMENTADAS

### 1. **Par√¢metros de Gera√ß√£o do Ollama** (REDUZ ALUCINA√á√ïES)

Adicionados par√¢metros cr√≠ticos no payload da API do Ollama:

```typescript
options: {
  temperature: 0.2,        // BAIXO = menos alucina√ß√µes (padr√£o: 0.7-0.9)
  top_p: 0.9,             // Nucleus sampling (padr√£o: 0.9)
  top_k: 40,              // Limita tokens considerados (padr√£o: 40)
  repeat_penalty: 1.1,     // Reduz repeti√ß√£o (padr√£o: 1.1)
  num_predict: 2048,      // Limite de tokens gerados
}
```

**Explica√ß√£o:**
- **Temperature 0.2**: Reduz criatividade, aumenta determinismo (menos alucina√ß√µes)
- **Top_p 0.9**: Considera apenas os 90% tokens mais prov√°veis
- **Top_k 40**: Limita a apenas 40 tokens mais prov√°veis por posi√ß√£o
- **Repeat_penalty 1.1**: Penaliza repeti√ß√£o de tokens

### 2. **SYSTEM_PROMPT Melhorado** (ZERO ALUCINA√á√ïES)

Adicionadas regras expl√≠citas:

```
REGRA CR√çTICA - ARQUIVOS E DIRET√ìRIOS (HONESTIDADE TOTAL - ZERO ALUCINA√á√ïES):
- üö® REGRA DE OURO: Se voc√™ N√ÉO VIU dados no contexto, N√ÉO INVENTE. Diga "N√£o tenho essa informa√ß√£o."
- SE N√ÉO HOUVER DADOS NO CONTEXTO: Diga "N√£o tenho essa informa√ß√£o" ao inv√©s de inventar
- EXEMPLO DE ALUCINA√á√ÉO (N√ÉO FA√áA): "Aqui est√£o os arquivos: package.json, App.tsx..." quando voc√™ N√ÉO VIU essa listagem
- EXEMPLO CORRETO: "N√£o consegui listar o diret√≥rio. O diret√≥rio pode n√£o existir ou n√£o tenho acesso."
```

### 3. **Tratamento de Erros Melhorado** (HONESTIDADE)

Backend (`server/agentTools.mjs`) agora retorna erros claros:

```javascript
{
  error: `HONESTIDADE: O diret√≥rio "${listPath}" N√ÉO EXISTE.`,
  requestedPath: parameters.dirPath,
  resolvedPath: listPath,
  suggestion: `Voc√™ pediu "${parameters.dirPath}". Eu resolvi para "${listPath}". Este caminho n√£o existe no sistema.`
}
```

---

## üìä COMPARA√á√ÉO: ANTES vs DEPOIS

### ‚ùå ANTES (ALUCINANDO):
```
Usu√°rio: "cara liste os componentes do disco c"
SuperEzio: "ls /dev/cdrom" (Linux, n√£o Windows!)
```

```
Usu√°rio: "o que eu tenho fixado na minha area de trabalho?"
SuperEzio: "package.json, App.tsx, script.sh, data.csv" (INVENTADO!)
```

### ‚úÖ DEPOIS (HONESTO):
```
Usu√°rio: "cara liste os componentes do disco c"
SuperEzio: "N√£o consegui listar o diret√≥rio C:\. O diret√≥rio pode n√£o existir ou n√£o tenho acesso."
```

```
Usu√°rio: "o que eu tenho fixado na minha area de trabalho?"
SuperEzio: "N√£o tenho essa informa√ß√£o. Preciso acessar sua √°rea de trabalho para ver."
```

---

## üîç COMO FUNCIONA AGORA

1. **Backend verifica se diret√≥rio existe** ‚Üí Retorna erro claro se n√£o existir
2. **Frontend passa contexto real** ‚Üí `[DIRET√ìRIO LISTADO]` ou `[ERRO]`
3. **Ollama recebe par√¢metros restritivos** ‚Üí `temperature: 0.2` (menos criatividade)
4. **SYSTEM_PROMPT instrui explicitamente** ‚Üí "N√ÉO INVENTE se n√£o viu dados"
5. **Modelo gera resposta baseada em contexto real** ‚Üí Sem alucina√ß√µes

---

## üß™ TESTES RECOMENDADOS

Ap√≥s reiniciar o servidor, teste:

1. **Diret√≥rio inexistente:**
   ```
   "listar pasta c"
   "verificar ./c"
   ```
   **Esperado:** "N√£o consegui listar o diret√≥rio. O diret√≥rio pode n√£o existir."

2. **Diret√≥rio existente:**
   ```
   "listar pasta src"
   "verificar ./src"
   ```
   **Esperado:** Lista real dos arquivos em `src/`

3. **Pergunta sem contexto:**
   ```
   "o que eu tenho fixado na minha area de trabalho?"
   ```
   **Esperado:** "N√£o tenho essa informa√ß√£o" (n√£o inventar arquivos)

---

## üìù ARQUIVOS MODIFICADOS

1. **`src/services/ollamaClient.ts`**:
   - Adicionado `options` ao `OllamaRequest`
   - Configurado `temperature: 0.2` e outros par√¢metros
   - Melhorado `SYSTEM_PROMPT` com regras anti-alucina√ß√£o

2. **`server/agentTools.mjs`**:
   - Melhorado tratamento de erros
   - Mensagens de erro com prefixo "HONESTIDADE:"
   - Verifica√ß√£o de exist√™ncia antes de listar

---

## üöÄ PR√ìXIMOS PASSOS

1. **Reiniciar servidor** para aplicar mudan√ßas
2. **Testar** com comandos que antes causavam alucina√ß√µes
3. **Ajustar temperature** se necess√°rio (0.1-0.3 para menos alucina√ß√µes, 0.4-0.6 para mais criatividade)
4. **Monitorar** se alucina√ß√µes persistem

---

## üìö REFER√äNCIAS

- [Ollama API Documentation](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [Temperature Parameter Explained](https://platform.openai.com/docs/api-reference/chat/create#temperature)
- [Reducing LLM Hallucinations](https://www.anthropic.com/research/reducing-hallucinations)

---

**Status:** ‚úÖ Implementado  
**Pr√≥ximo:** Testar e validar redu√ß√£o de alucina√ß√µes

