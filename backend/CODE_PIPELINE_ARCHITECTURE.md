# Code Pipeline - Arquitetura de 3 Modelos

## Vis√£o Geral

O **Code Pipeline** √© uma arquitetura sofisticada de 3 est√°gios que orquestra m√∫ltiplos modelos para gerar c√≥digo de alta qualidade.

### Conceito

```
User Query ‚Üí ROUTER ‚Üí Code Expert? 
                           ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  PLANNER     ‚îÇ (Qwen local + RAG + SuperEzio)
                    ‚îÇ  Stage 1     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚Üì (plan.json)
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  CODER       ‚îÇ (DeepSeek-Coder ou Qwen)
                    ‚îÇ  Stage 2     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚Üì (code.json)
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  REVIEWER    ‚îÇ (LLaMA 3 ou Qwen)
                    ‚îÇ  Stage 3     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚Üì (final_answer.md)
                    üìù User Response
```

---

## Arquitetura Detalhada

### Stage 1: PLANNER (Qwen2.5-7B Local)

**Responsabilidades:**
- Entender pedido do usu√°rio em profundidade
- Analisar contexto RAG dispon√≠vel
- Identificar constraints (Windows, Python 3.11, etc.)
- Gerar plano estruturado em JSON
- Sugerir API design se aplic√°vel

**Modelo:** Qwen2.5-7B-Instruct (local, 4-bit)  
**Persona:** SuperEzio-Code Planner  
**Temperature:** 0.3 (determin√≠stico)  
**Max Tokens:** 1024

**Sa√≠da JSON:**
```json
{
  "stage": "planner",
  "expert": "code_python",
  "goal": "Criar API REST para gerenciar usu√°rios",
  "context_used": ["FastAPI patterns", "SQLAlchemy ORM"],
  "constraints": ["Windows PowerShell", "Python 3.11", "FastAPI"],
  "api_design": {
    "endpoints": ["/users", "/users/{id}"],
    "classes": ["User", "UserService"],
    "functions": ["create_user", "get_user"]
  },
  "reasoning": "FastAPI √© ideal para APIs REST modernas"
}
```

---

### Stage 2: CODER (DeepSeek-Coder ou Fallback)

**Responsabilidades:**
- Receber plano do Stage 1
- Gerar c√≥digo completo e funcional
- Criar arquivos necess√°rios
- Sugerir comandos para executar
- Considerar edge cases e error handling

**Modelo Preferido:** DeepSeek-Coder-6.7B-Instruct (HF Inference API)  
**Fallback:** Qwen2.5-7B local  
**Persona:** DeepSeek-Code Executor  
**Temperature:** 0.2 (baixa para c√≥digo)  
**Max Tokens:** 2048

**Sa√≠da JSON:**
```json
{
  "stage": "coder",
  "expert": "code_python",
  "files_to_create": [
    {
      "path": "backend/service.py",
      "language": "python",
      "content": "from fastapi import FastAPI\n..."
    }
  ],
  "files_to_update": [],
  "cmd_instructions": [
    "pip install fastapi uvicorn",
    "python backend/service.py"
  ],
  "notes": "C√≥digo usa type hints e async/await"
}
```

---

### Stage 3: REVIEWER (LLaMA 3 ou Fallback)

**Responsabilidades:**
- Revisar c√≥digo do Stage 2
- Identificar bugs, vulnerabilidades, problemas
- Verificar se atende plano original
- Sugerir patches se necess√°rio
- Gerar resposta final em Markdown

**Modelo Preferido:** LLaMA-3-8B-Instruct (HF Inference API)  
**Fallback:** Qwen2.5-7B local  
**Persona:** LLaMA-3 Reviewer  
**Temperature:** 0.4 (criativo para explica√ß√µes)  
**Max Tokens:** 2048

**Sa√≠da JSON:**
```json
{
  "stage": "review",
  "expert": "code_python",
  "status": "ok",
  "issues": [],
  "suggested_patches": [],
  "final_answer_markdown": "# API REST com FastAPI\n\n..."
}
```

---

## Experts de C√≥digo

Todos os seguintes experts usam o pipeline automaticamente:

1. **code_python** - Python, FastAPI, Django, pandas, PyTorch
2. **code_ts** - TypeScript, React, Next.js, Node.js
3. **code_js** - JavaScript puro
4. **code_infra** - Docker, Kubernetes, CI/CD
5. **code_ml** - Machine Learning, LoRA, transformers
6. **code_database** - SQL, PostgreSQL, MongoDB
7. **code_frontend** - React, Vue, CSS, Tailwind
8. **code_api** - REST APIs, GraphQL, OpenAPI
9. **code_testing** - pytest, Jest, TDD
10. **code_algorithms** - Data structures, complexidade
11. **code_hf_curator** - HuggingFace models e datasets
12. **code_general** - Programa√ß√£o geral

---

## Integra√ß√£o com Sistema Existente

### Fluxo Completo

```python
# 1. User faz request para /api/chat
POST /api/chat
{
  "messages": [{"role": "user", "content": "Crie uma API REST Python"}],
  "model": "Qwen2.5-7B-Instruct"
}

# 2. api.py ‚Üí inference.py ‚Üí chat_completion()

# 3. MoE Router decide expert
router.route(messages) ‚Üí "code_python"

# 4. Detecta code expert
is_code_expert("code_python") ‚Üí True

# 5. Executa pipeline
run_code_pipeline(messages, "code_python", rag_context)

# 6. Pipeline retorna resultado final
{
  "content": "# API REST com FastAPI\n\n...",
  "expert": "code_python",
  "pipeline_stages": {...},
  "pipeline_duration_ms": 8500
}

# 7. api.py retorna para cliente
{
  "id": "chatcmpl-...",
  "choices": [{
    "message": {
      "role": "assistant",
      "content": "# API REST com FastAPI\n\n..."
    }
  }]
}
```

### C√≥digo de Integra√ß√£o (inference.py)

```python
from code_pipeline import run_code_pipeline, is_code_expert

def chat_completion(messages, tools, temperature, max_tokens, stream, mode):
    # ... existing MoE routing ...
    
    # CODE PIPELINE CHECK
    if is_code_expert(decision.expert_id):
        print(f"üöÄ [MOE] Code expert detected ‚Üí Using 3-stage pipeline")
        pipeline_result = run_code_pipeline(
            messages=messages,
            expert_id=decision.expert_id,
            rag_context=rag_system_message
        )
        
        return {
            "content": pipeline_result["content"],
            "expert": pipeline_result["expert"],
            "pipeline_stages": pipeline_result.get("pipeline_stages", {}),
            "pipeline_duration_ms": pipeline_result.get("pipeline_duration_ms", 0),
            "lora_adapter": decision.lora_adapter,
            "rag_domains": decision.rag_domains
        }
    
    # ... continue with standard flow for non-code experts ...
```

---

## Vantagens do Pipeline

### 1. Especializa√ß√£o de Tarefas
- **Planner:** Foco em arquitetura e design
- **Coder:** Foco em implementa√ß√£o
- **Reviewer:** Foco em qualidade e corre√ß√£o

### 2. Qualidade do C√≥digo
- Revis√£o autom√°tica em 3 camadas
- Detec√ß√£o de bugs antes de entregar ao usu√°rio
- Sugest√£o de melhorias e patches

### 3. Context Awareness
- RAG integration no Stage 1
- Plano guia o Coder no Stage 2
- Reviewer valida contra plano original

### 4. Flexibilidade
- Fallback para Qwen local se APIs externas falham
- Pode usar modelos diferentes por stage
- Logs detalhados para debug

### 5. Escalabilidade
- F√°cil adicionar novos experts
- Pode substituir modelos por stage
- Pipeline isolado do resto do sistema

---

## Configura√ß√£o

### Vari√°veis de Ambiente

```bash
# HuggingFace Inference API (para Stage 2 e 3)
export HF_TOKEN="hf_..."

# OpenRouter API (alternativa)
export OPENROUTER_API_KEY="sk-or-..."
```

### Fallback Autom√°tico

Se as APIs n√£o estiverem configuradas, o sistema usa **Qwen local** para todos os 3 est√°gios:

```
Stage 1: Qwen local (sempre)
Stage 2: DeepSeek API ‚Üí Qwen local (fallback)
Stage 3: LLaMA 3 API ‚Üí Qwen local (fallback)
```

---

## Performance

### Timing Esperado

```
Stage 1 (Planner):  1-3 segundos
Stage 2 (Coder):    3-6 segundos
Stage 3 (Reviewer): 2-4 segundos
Total:              6-13 segundos
```

### Otimiza√ß√µes Futuras

1. **Cache de Planos:** Planos similares podem ser reutilizados
2. **Paraleliza√ß√£o:** Stage 2 e 3 podem rodar em paralelo para review parcial
3. **Streaming:** Retornar Stage 2 enquanto Stage 3 processa
4. **Batch Processing:** Processar m√∫ltiplos arquivos em paralelo

---

## Testes

### Executar Test Suite

```powershell
cd backend
python test_code_pipeline.py
```

### Testes Inclu√≠dos

1. ‚úÖ **Expert Detection:** Valida is_code_expert()
2. ‚úÖ **Python Pipeline:** Testa code_python end-to-end
3. ‚úÖ **TypeScript Pipeline:** Testa code_ts
4. ‚úÖ **Infrastructure Pipeline:** Testa code_infra
5. ‚úÖ **RAG Context:** Testa pipeline com RAG injection

---

## Debug

### Logs Detalhados

O pipeline gera logs estruturados:

```
================================================================================
[PIPELINE][PLANNER] Stage 1: Planning
  Expert: code_python
  RAG Context: Yes
================================================================================

‚úÖ [PLANNER] Plan generated in 1850ms
   Goal: Criar API REST para gerenciar usu√°rios
   Constraints: 3

================================================================================
[PIPELINE][CODER] Stage 2: Code Generation
  Expert: code_python
  Plan: Criar API REST para gerenciar usu√°rios...
================================================================================

‚úÖ [CODER] Code generated in 4200ms
   Files: 2, Commands: 3

================================================================================
[PIPELINE][REVIEWER] Stage 3: Code Review
  Expert: code_python
================================================================================

‚úÖ [REVIEWER] Review completed in 3100ms
   Status: ok, Issues: 0

################################################################################
# PIPELINE COMPLETED
# Total time: 9150ms
#   Stage 1 (Planner):  1850ms
#   Stage 2 (Coder):    4200ms
#   Stage 3 (Reviewer): 3100ms
################################################################################
```

### Desabilitar Debug

```python
# code_pipeline.py
DEBUG_PIPELINE = False
```

---

## Exemplos de Uso

### Exemplo 1: API REST Python

**Input:**
```
Crie uma API REST em Python com FastAPI para gerenciar usu√°rios
```

**Pipeline Flow:**
1. Planner: Identifica FastAPI, SQLAlchemy, CRUD operations
2. Coder: Gera main.py, models.py, schemas.py
3. Reviewer: Valida c√≥digo, adiciona error handling

**Output:**
```markdown
# API REST com FastAPI

Criei uma API completa com 3 arquivos:

## 1. models.py
```python
from sqlalchemy import Column, Integer, String
...
```

## 2. schemas.py
```python
from pydantic import BaseModel
...
```

## 3. main.py
```python
from fastapi import FastAPI
...
```

## Como Executar

```powershell
pip install fastapi uvicorn sqlalchemy
uvicorn main:app --reload
```

Acesse: http://localhost:8000/docs
```

---

### Exemplo 2: React Component

**Input:**
```
Crie um componente React TypeScript com lista de usu√°rios e pagina√ß√£o
```

**Pipeline Flow:**
1. Planner: Identifica React, TypeScript, hooks, state management
2. Coder: Gera UserList.tsx com useState, useEffect
3. Reviewer: Adiciona loading state, error handling

**Output:**
```markdown
# Componente UserList

```typescript
import React, { useState, useEffect } from 'react';

interface User {
  id: number;
  name: string;
  email: string;
}

export const UserList: React.FC = () => {
  const [users, setUsers] = useState<User[]>([]);
  const [page, setPage] = useState(1);
  const [loading, setLoading] = useState(false);
  
  // ... c√≥digo completo ...
};
```

## Como Usar

```powershell
npm install react
# Importe em App.tsx: import { UserList } from './UserList';
```
```

---

## Roadmap

### Fase 1: MVP (ATUAL) ‚úÖ
- [x] Pipeline de 3 est√°gios
- [x] Integra√ß√£o com MoE Router
- [x] Fallback para Qwen local
- [x] Logs detalhados
- [x] Test suite

### Fase 2: APIs Externas
- [ ] Integra√ß√£o com DeepSeek-Coder API
- [ ] Integra√ß√£o com LLaMA 3 API
- [ ] Retry logic e rate limiting
- [ ] Cache de respostas

### Fase 3: Otimiza√ß√µes
- [ ] Streaming de Stage 2 enquanto Stage 3 processa
- [ ] Paraleliza√ß√£o de tasks
- [ ] Cache de planos similares
- [ ] Batch processing

### Fase 4: Melhorias
- [ ] Tool calling integration
- [ ] File creation autom√°tica
- [ ] Git commit suggestions
- [ ] Interactive refinement

---

## FAQ

### Q: Por que 3 modelos e n√£o 1?

**A:** Especializa√ß√£o de tarefas. Cada modelo foca em uma coisa:
- Qwen: Planejamento e contexto
- DeepSeek: Gera√ß√£o de c√≥digo (especialista)
- LLaMA: Revis√£o e explica√ß√£o

### Q: E se as APIs falharem?

**A:** Fallback autom√°tico para Qwen local. O sistema sempre funciona.

### Q: Posso desabilitar o pipeline?

**A:** Sim. Comente a linha em `inference.py`:
```python
# if is_code_expert(decision.expert_id):
#     pipeline_result = run_code_pipeline(...)
```

### Q: Como adicionar um novo expert de c√≥digo?

**A:** 
1. Adicione em `expert_registry.py` com ID come√ßando com `code_`
2. Adicione keywords relevantes
3. Pipeline detecta automaticamente

### Q: Qual o custo de usar APIs externas?

**A:** 
- DeepSeek-Coder: ~$0.14/1M tokens
- LLaMA 3-8B: ~$0.18/1M tokens
- Por query: ~$0.001-0.003 (1-3 cents)

---

## Conclus√£o

O **Code Pipeline** √© uma arquitetura robusta que combina:
- ‚úÖ Planejamento inteligente (Qwen + RAG + SuperEzio)
- ‚úÖ C√≥digo especializado (DeepSeek-Coder)
- ‚úÖ Revis√£o de qualidade (LLaMA 3)
- ‚úÖ Fallback autom√°tico
- ‚úÖ Integra√ß√£o transparente

**Resultado:** C√≥digo de alta qualidade, revisado e explicado, em portugu√™s coloquial.

---

**Autor:** Marco Barreto  
**Projeto:** Superezio Realtime  
**Data:** 2025-01-13  
**Vers√£o:** 1.0.0
